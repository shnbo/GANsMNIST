import numpy as np
import matplotlib.pyplot as plt
import time

from keras.models import Sequential
from keras.layers import Dense
from keras.layers import LeakyReLU
from keras.layers import Conv2DTranspose
from keras.layers import Conv2D
from keras.layers import Reshape
from keras.layers import Dropout
from keras.layers import Flatten
from keras.optimizers import Adam

from keras.datasets import mnist

def buildGenerator(latent_dim):
    model = Sequential()

    model.add(Dense(7*7*256, input_dim=latent_dim))
    model.add(LeakyReLU(alpha=0.2))
    model.add(Reshape((7, 7, 256)))

    model.add(Conv2DTranspose(256, kernel_size=(2,2), strides=(2,2), activation='relu',
                              kernel_initializer='he_normal', padding='same'))
    model.add(LeakyReLU(alpha=0.2))

    model.add(Conv2DTranspose(256, kernel_size=(2,2), strides=(2,2), activation='relu',
                              kernel_initializer='he_normal', padding='same'))
    model.add(LeakyReLU(alpha=0.2))

    model.add(Conv2D(1, kernel_size=(4,4), activation='sigmoid', padding='same'))

    model.summary()

    return model

def buildDiscriminator():
    model = Sequential()

    model.add(Conv2D(128, kernel_size=(3, 3), strides=(2,2), padding='same', input_shape=(28, 28, 1)))
    model.add(LeakyReLU(alpha=0.2))
    model.add(Dropout(0.3))

    model.add(Conv2D(128, kernel_size=(3,3), strides=(2,2), padding='same'))
    model.add(LeakyReLU(alpha=0.2))
    model.add(Dropout(0.3))

    model.add(Flatten())
    model.add(Dense(1, activation='sigmoid'))

    model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5), metrics=['accuracy'])

    model.summary()

    return model

def buildGAN(gModel, dModel):
    dModel.trainable = False

    model = Sequential()
    model.add(gModel)
    model.add(dModel)

    model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5), metrics=['accuracy'])

    model.summary()

    return model

def train(gModel, dModel, ganModel, latent_dim, epochs, batchSize=128):
    # data load
    (trainX, _), (_, _) = mnist.load_data()

    # normalization
    trainX = np.expand_dims(trainX, axis=-1)
    trainX = trainX.astype(np.float32)
    trainX = trainX / 255.0

    # data preparation
    halfBatch = int(batchSize / 2)
    for idx in range(epochs):
        idxReal = np.random.randint(0, trainX.shape[0], halfBatch)
        xReal = trainX[idxReal]
        yReal = np.ones((halfBatch, 1))

        noise = np.random.randn((latent_dim*halfBatch)).reshape((halfBatch, latent_dim))
        xFake = gModel.predict(noise)
        yFake = np.zeros((halfBatch, 1))

        xDis = np.vstack((xReal, xFake))
        yDis = np.vstack((yReal, yFake))

        xGan = np.random.randn(batchSize*latent_dim).reshape((batchSize, latent_dim))
        yGan = np.ones((batchSize, 1))

    # train data
        d_loss, _ = dModel.train_on_batch(xDis, yDis)
        gan_loss, _ = ganModel.train_on_batch(xGan, yGan)

    # model save
        if (idx+1) % 500 == 0:
            print("epoch : %d, d_loss = %f, gan_loss = %f" % (idx+1, d_loss, gan_loss))

            n = np.random.randn(25*latent_dim).reshape((25, latent_dim))
            img = gModel.predict(n)

            for i in range(25):
                plt.subplot(5, 5, i+1)
                plt.imshow(img[i, :, :, 0], cmap='gray_r')
            plt.savefig('generated image on epoch %d.png' % (idx+1))
            plt.close()

            ganModel.save('GAN model on epoch %d.h5' % (idx+1))


latent_dim = 100
epochs = 10000

gModel = buildGenerator(latent_dim)
dModel = buildDiscriminator()
ganModel = buildGAN(gModel, dModel)

start = time.time()
train(gModel, dModel, ganModel, latent_dim, epochs)
print('training done elapsed time : %.3f sec' % (time.time()-start))
